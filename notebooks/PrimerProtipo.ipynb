{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eed7acb",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è **Primer prototipo o pruebas con datos**\n",
    "\n",
    "En esta etapa necesitamos:\n",
    "\n",
    "1. **Cargar** una oraci√≥n de prueba.\n",
    "2. **Definir** manualmente los par√°metros del HMM (œÄ, A, B).\n",
    "3. **Preparar estructuras** para procesarlas en c√≥digo.\n",
    "\n",
    "### üìò TEOR√çA DE HMM (Modelo Oculto de Markov)\n",
    "\n",
    "Seg√∫n Rabiner:\n",
    "\n",
    "- Un HMM es un modelo estad√≠stico probabil√≠stico en el que se asume que el sistema que se modela es un proceso de Markov con estados ocultos. donde:\n",
    "    - El estado actual influye en los estados futuros, pero los estados en s√≠ no son directamente observables.\n",
    "    - Hay una secuencia de observaciones conocidas, lo que observamos son **emisiones** o **observaciones** que dependen del estado oculto actual.\n",
    "    - Hay una secuencia de **estados ocultos** desconocidos que queremos inferir.\n",
    "- Se compone de:\n",
    "    - **Conjunto de estados ocultos (S):** Un n√∫mero finito de estados que no son directamente observables. En el contexto del POS-tagging, estos estados representar√≠an las posibles etiquetas gramaticales (sustantivo, verbo, adjetivo, etc.).\n",
    "    - **Conjunto de observaciones (V):** Un n√∫mero finito de s√≠mbolos de observaci√≥n que son las salidas del sistema que podemos observar. En el POS-tagging, estas ser√≠an las palabras del texto que queremos etiquetar.\n",
    "- Se caracteriza por 3 conjuntos de par√°metros:\n",
    "    - **Matriz de probabilidades de transici√≥n de estados (A):** Define la probabilidad de transici√≥n entre los estados ocultos. $a_{ij} = P(q_{t+1} = S_j | q_t = S_i)$ es la probabilidad de estar en el estado $S_i$  en el tiempo $t$ y pasar al estado $S_j$ en el tiempo $t+1$.  ***(probabilidad de pasar de una etiqueta a otra)***\n",
    "    - **Matriz de probabilidades de emisi√≥n (B):** Define la probabilidad de observar un s√≠mbolo particular dado un estado oculto. $b_j(k) = P(O_t = v_k | q_t = S_j)$ es la probabilidad de observar el s√≠mbolo $v_k$ cuando el estado oculto en el tiempo $t$ es $S_j$. ***(probabilidad de que una palabra sea generada por una etiqueta.)***\n",
    "    - **Vector de probabilidades iniciales de estado (œÄ):** Define la probabilidad de estar en un estado particular en el tiempo inicial ($t=1$).\n",
    "        \n",
    "         $\\pi_i = P(q_1 = S_i)$ es la probabilidad de que el primer estado oculto sea $S_i$. ***(probabilidad de comenzar en cada etiqueta.)***\n",
    "        \n",
    "\n",
    "**HMM de Primer Orden**\n",
    "\n",
    "Un HMM de primer orden se caracteriza por la **propiedad de Markov de primer orden**, que establece que la probabilidad del estado actual solo depende del estado inmediatamente anterior. Matem√°ticamente, esto se expresa como:\n",
    "\n",
    "$P(q_t | q_{t-1}, q_{t-2}, ..., q_1) = P(q_t | q_{t-1})$\n",
    "\n",
    "De manera similar, la probabilidad de una observaci√≥n en un momento dado solo depende del estado oculto en ese mismo momento:\n",
    "\n",
    "$P(O_t | q_1, ..., q_t, O_1, ..., O_{t-1}) = P(O_t | q_t)$\n",
    "\n",
    "**HMM para POS-Tagging**\n",
    "\n",
    "En el contexto del POS-tagging, podemos mapear los componentes de un HMM de la siguiente manera:\n",
    "\n",
    "- **Estados ocultos (S):** El conjunto de posibles etiquetas gramaticales (e.g., {NOUN, VERB, ADJ, DET}).\n",
    "- **Observaciones (V):** El vocabulario del idioma (el conjunto de todas las palabras posibles).\n",
    "- **Probabilidades de transici√≥n (A):** La probabilidad de que una etiqueta gramatical siga a otra (e.g., la probabilidad de que un sustantivo siga a un determinante). Estas probabilidades se pueden estimar a partir de un corpus de texto etiquetado.\n",
    "- **Probabilidades de emisi√≥n (B):** La probabilidad de que una palabra particular sea generada por una etiqueta gramatical espec√≠fica (e.g., la probabilidad de que la palabra \"gato\" tenga la etiqueta NOUN). Estas probabilidades tambi√©n se pueden estimar a partir de un corpus de texto etiquetado.\n",
    "- **Probabilidades iniciales (œÄ):** La probabilidad de que una etiqueta gramatical sea la primera etiqueta en una oraci√≥n (e.g., la probabilidad de que la primera palabra de una oraci√≥n sea un determinante o un sustantivo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba2b27",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
