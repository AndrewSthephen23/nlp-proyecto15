{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ ¬øQu√© haremos en esta parte?\n",
        "\n",
        "### **Objetivo**:\n",
        "\n",
        "Usar el **Brown Corpus** (un corpus etiquetado del ingl√©s) para:\n",
        "\n",
        "- Probar el algoritmo de Viterbi.\n",
        "- Validar los resultados en una oraci√≥n real etiquetada.\n",
        "- Comparar la secuencia etiquetada con la secuencia ‚Äúverdadera‚Äù.\n",
        "\n",
        "## üîß PASOS PARA AVANZAR:\n",
        "\n",
        "### üì¶ Paso 1: Instalar y cargar el corpus Brown\n",
        "\n",
        "Usaremos **NLTK**, una librer√≠a muy com√∫n para NLP en Python.\n",
        "\n",
        "```bash\n",
        "pip install nltk\n",
        "```\n",
        "\n",
        "C√≥digo para cargar una parte del corpus:"
      ],
      "metadata": {
        "id": "LPdpJlJF_lDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3lXVJ62j07Z",
        "outputId": "02c26131-06dc-47bd-8297-4e5d48f7dbf3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "- Se importa la biblioteca **NLTK (Natural Language Toolkit)**, una de las bibliotecas m√°s utilizadas en Python para procesamiento de lenguaje natural. Contiene herramientas para tareas como tokenizaci√≥n, etiquetado gramatical (POS tagging), an√°lisis sint√°ctico, etc.\n",
        "- Se descarga el **Brown Corpus**, uno de los corpus m√°s antiguos y ampliamente utilizados en ling√º√≠stica computacional. Es una colecci√≥n de textos en ingl√©s estadounidense divididos en categor√≠as tem√°ticas. Se usa para entrenar y probar modelos de lenguaje, an√°lisis gramatical, etc.\n",
        "- Se descarga el **Universal Tagset**, que es un conjunto simplificado y estandarizado de etiquetas gramaticales (como `NOUN`, `VERB`, `ADJ`, etc.). Sirve para facilitar comparaciones entre lenguajes o corpus que utilizan diferentes conjuntos de etiquetas.\n",
        "\n",
        "\n",
        "‚úÖ **Resumen Visual:**\n",
        "\n",
        "```\n",
        "[NLTK] ---> [Brown Corpus üìò] + [Universal POS Tags üè∑Ô∏è]\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Luego, cargamos las oraciones etiquetadas con un **tagset universal** (simplificado, como NOUN, VERB, etc.):"
      ],
      "metadata": {
        "id": "oLUJx19PAHRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "\n",
        "# Obtener oraciones etiquetadas (solo las 5000 primeras para empezar)\n",
        "tagged_sents = brown.tagged_sents(tagset='universal')[:5000]\n",
        "tagged_sents[:1] # Visualizacion de la primera oracion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUCuW-kXj8QU",
        "outputId": "1c7706dc-a07d-441b-ec47-2fa8d8f7691e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('The', 'DET'),\n",
              "  ('Fulton', 'NOUN'),\n",
              "  ('County', 'NOUN'),\n",
              "  ('Grand', 'ADJ'),\n",
              "  ('Jury', 'NOUN'),\n",
              "  ('said', 'VERB'),\n",
              "  ('Friday', 'NOUN'),\n",
              "  ('an', 'DET'),\n",
              "  ('investigation', 'NOUN'),\n",
              "  ('of', 'ADP'),\n",
              "  (\"Atlanta's\", 'NOUN'),\n",
              "  ('recent', 'ADJ'),\n",
              "  ('primary', 'NOUN'),\n",
              "  ('election', 'NOUN'),\n",
              "  ('produced', 'VERB'),\n",
              "  ('``', '.'),\n",
              "  ('no', 'DET'),\n",
              "  ('evidence', 'NOUN'),\n",
              "  (\"''\", '.'),\n",
              "  ('that', 'ADP'),\n",
              "  ('any', 'DET'),\n",
              "  ('irregularities', 'NOUN'),\n",
              "  ('took', 'VERB'),\n",
              "  ('place', 'NOUN'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "- Se importa el **corpus Brown** desde el m√≥dulo `nltk.corpus`. Esto nos da acceso directo al contenido del corpus, como palabras, oraciones y sus etiquetas gramaticales.\n",
        "- `brown.tagged_sents(tagset='universal')`:\n",
        "    - Esto obtiene las oraciones del corpus **Brown**, donde cada palabra est√° **etiquetada gramaticalmente** (por ejemplo: 'the/DET', 'dog/NOUN').\n",
        "    - El par√°metro `tagset='universal'` convierte las etiquetas del corpus a un conjunto **simplificado y estandarizado** de etiquetas gramaticales universales (como `NOUN`, `VERB`, `ADP`, etc.), en lugar del conjunto original del Brown Corpus.\n",
        "---\n",
        "\n",
        "### üß† Paso 2: Extraer listas de etiquetas y palabras\n",
        "\n",
        "Vamos a obtener todas las **etiquetas** y **palabras** del corpus y crear un **vocabulario y conjunto de etiquetas √∫nicos**:"
      ],
      "metadata": {
        "id": "cWT8d7-BAVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listas vac√≠as para almacenar\n",
        "tag_sequences = []\n",
        "word_sequences = []\n",
        "\n",
        "for sent in tagged_sents:\n",
        "    words, tags = zip(*sent)\n",
        "    word_sequences.append(list(words))\n",
        "    tag_sequences.append(list(tags))\n",
        "\n",
        "print(\"Word despues del Zip\", words)\n",
        "print(\"Tags despues del Zip\", tags)\n",
        "print(\"Word secuence\", word_sequences[-2:])\n",
        "print(\"Tag secuence\", tag_sequences[-2:])\n",
        "\n",
        "\n",
        "# Vocabulario de palabras y etiquetas\n",
        "all_tags = sorted(set(tag for tags in tag_sequences for tag in tags))\n",
        "all_words = sorted(set(word.lower() for words in word_sequences for word in words))\n",
        "\n",
        "# Crear √≠ndices\n",
        "tag2idx = {tag: i for i, tag in enumerate(all_tags)}\n",
        "word2idx = {word: i for i, word in enumerate(all_words)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbpUa5cLL3x4",
        "outputId": "4c2f85b8-69df-468d-908a-cc0957fe29df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word despues del Zip ('Does', 'it', 'attack', 'other', 'traditional', 'American', 'institutions', 'with', 'unsupportable', 'and', 'wild', 'charges', '?', '?')\n",
            "Tags despues del Zip ('VERB', 'PRON', 'VERB', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'CONJ', 'ADJ', 'NOUN', '.', '.')\n",
            "Word secuence [['2', '.'], ['Does', 'it', 'attack', 'other', 'traditional', 'American', 'institutions', 'with', 'unsupportable', 'and', 'wild', 'charges', '?', '?']]\n",
            "Tag secuence [['NUM', '.'], ['VERB', 'PRON', 'VERB', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'CONJ', 'ADJ', 'NOUN', '.', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Todas las palabras\", all_words[900:920])\n",
        "print(\"Todas las etiquetas\", all_tags)\n",
        "print(\"Indices de palabras\", dict(list(word2idx.items())[900:920]))\n",
        "print(\"Indices de etiquetas\", tag2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78kZnwgKWcAh",
        "outputId": "d3146ff8-dcfa-496a-dd10-b56aba899580"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todas las palabras ['accused', 'ace', 'achaeans', \"achaeans'\", 'achieve', 'achieved', 'achievement', 'achievements', 'achieves', 'aching', 'acid', 'acknowledge', 'acknowledged', 'acknowledging', 'acknowledgment', 'acquaint', 'acquaintance', 'acquiesce', 'acquiesced', 'acquire']\n",
            "Todas las etiquetas ['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "Indices de palabras {'accused': 900, 'ace': 901, 'achaeans': 902, \"achaeans'\": 903, 'achieve': 904, 'achieved': 905, 'achievement': 906, 'achievements': 907, 'achieves': 908, 'aching': 909, 'acid': 910, 'acknowledge': 911, 'acknowledged': 912, 'acknowledging': 913, 'acknowledgment': 914, 'acquaint': 915, 'acquaintance': 916, 'acquiesce': 917, 'acquiesced': 918, 'acquire': 919}\n",
            "Indices de etiquetas {'.': 0, 'ADJ': 1, 'ADP': 2, 'ADV': 3, 'CONJ': 4, 'DET': 5, 'NOUN': 6, 'NUM': 7, 'PRON': 8, 'PRT': 9, 'VERB': 10, 'X': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "| Parte | Descripci√≥n |\n",
        "| --- | --- |\n",
        "| `tag_sequences`, `word_sequences` | üìÑ Listas para guardar solo las palabras y etiquetas de cada oraci√≥n |\n",
        "| `zip(*sent)` | Separa cada oraci√≥n etiquetada en dos listas: palabras y etiquetas |\n",
        "| `set(... for ...)` | Extrae todas las **palabras √∫nicas** (en min√∫scula) y **etiquetas √∫nicas** |\n",
        "| `enumerate(...)` | Asigna un **√≠ndice num√©rico** a cada palabra y etiqueta |\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **Resumen visual paso a paso:**\n",
        "\n",
        "```\n",
        "1. [('The', 'DET'), ('dog', 'NOUN')] ‚Üí zip ‚Üí ['The', 'dog'], ['DET', 'NOUN']\n",
        "2. word_sequences = [['The', 'dog'], ...]\n",
        "3. tag_sequences  = [['DET', 'NOUN'], ...]\n",
        "\n",
        "4. all_words = ['a', 'about', 'accident', ...]  ‚Üí word2idx = {'a': 0, 'about': 1, ...}\n",
        "5. all_tags  = ['ADJ', 'ADV', 'DET', ...]      ‚Üí tag2idx  = {'ADJ': 0, 'ADV': 1, ...}\n",
        "```\n",
        "---\n",
        "\n",
        "## üéØ Paso 3: Estimar œÄ (probabilidades iniciales)\n",
        "\n",
        "La probabilidad œÄ representa qu√© **tan seguido cada etiqueta inicia una oraci√≥n**:"
      ],
      "metadata": {
        "id": "5PH1AeK7RNS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_tags = len(all_tags)\n",
        "pi = np.zeros(num_tags)\n",
        "\n",
        "# Contar cu√°ntas veces comienza una oraci√≥n con cada etiqueta\n",
        "for tags in tag_sequences:\n",
        "    first_tag = tags[0]\n",
        "    pi[tag2idx[first_tag]] += 1\n",
        "\n",
        "# Normalizar\n",
        "pi /= pi.sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "kmhqOtakRglD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimire pi mostrando a que etiqueta corresponde esa probabilida y cual fue su conteo\n",
        "for i, p in enumerate(pi):\n",
        "    print(f\"{all_tags[i]}: {p:.4f} ({pi[i] * len(tag_sequences):.0f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se-i5gvaeTG6",
        "outputId": "c7b618c7-98c2-4ce2-9c8c-79e431762113"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".: 0.0824 (412)\n",
            "ADJ: 0.0460 (230)\n",
            "ADP: 0.1006 (503)\n",
            "ADV: 0.0578 (289)\n",
            "CONJ: 0.0380 (190)\n",
            "DET: 0.2470 (1235)\n",
            "NOUN: 0.2520 (1260)\n",
            "NUM: 0.0164 (82)\n",
            "PRON: 0.0952 (476)\n",
            "PRT: 0.0272 (136)\n",
            "VERB: 0.0368 (184)\n",
            "X: 0.0006 (3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "### Vector de estados iniciales `œÄ`\n",
        "\n",
        "```python\n",
        "num_tags = len(all_tags)     # Total de etiquetas (estados)\n",
        "pi = np.zeros(num_tags)      # Inicializa un vector de ceros\n",
        "```\n",
        "\n",
        "Se crea un vector llamado `pi` que guardar√° **la probabilidad de comenzar una oraci√≥n con cada etiqueta gramatical**.\n",
        "\n",
        "Visualmente ser√≠a algo as√≠ como:\n",
        "\n",
        "```\n",
        "pi = [0, 0, 0, 0, ...]  ‚Üê uno por cada etiqueta (NOUN, VERB, DET, etc.)\n",
        "```\n",
        "\n",
        "### Contar etiquetas iniciales\n",
        "\n",
        "```python\n",
        "for tags in tag_sequences:\n",
        "    first_tag = tags[0]\n",
        "    pi[tag2idx[first_tag]] += 1\n",
        "```\n",
        "\n",
        "Recorre todas las oraciones y **cuenta con qu√© etiqueta comienza cada una**.\n",
        "\n",
        "Ejemplo\n",
        "\n",
        "- Si una oraci√≥n empieza con `DET`, suma 1 al √≠ndice correspondiente en `pi`.\n",
        "\n",
        "### Normalizaci√≥n\n",
        "\n",
        "```python\n",
        "pi /= pi.sum()\n",
        "```\n",
        "\n",
        "Convierte los conteos en **probabilidades reales** (todas suman 1).\n",
        "\n",
        "üìä Ejemplo conceptual:\n",
        "\n",
        "| Etiqueta inicial | Conteo | Probabilidad (œÄ) |\n",
        "| --- | --- | --- |\n",
        "| DET | 2000 | 0.40 |\n",
        "| NOUN | 1500 | 0.30 |\n",
        "| VERB | 1500 | 0.30 |\n",
        "\n",
        "---\n",
        "\n",
        "## üîÑ Paso 4: Estimar A (matriz de transici√≥n)\n",
        "\n",
        "La matriz A cuenta la frecuencia con que una etiqueta es seguida por otra:"
      ],
      "metadata": {
        "id": "A7bEnzsBdoLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.zeros((num_tags, num_tags))\n",
        "\n",
        "for tags in tag_sequences:\n",
        "    for i in range(1, len(tags)):\n",
        "        prev_tag = tags[i-1]\n",
        "        curr_tag = tags[i]\n",
        "        A[tag2idx[prev_tag], tag2idx[curr_tag]] += 1\n",
        "\n",
        "# Normalizar por filas (para que cada fila sume 1)\n",
        "A = A / A.sum(axis=1, keepdims=True)\n"
      ],
      "metadata": {
        "id": "G51-w0eCd2oa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#imprimire la matriz A donde las columas y filas tengan de nombre las etiquetas\n",
        "print(pd.DataFrame(A, index=all_tags, columns=all_tags).round(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0ECtdQYfmE3",
        "outputId": "849cfbfb-2c85-40d4-a73b-2ee0b2f8787d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          .    ADJ    ADP    ADV   CONJ    DET   NOUN    NUM   PRON    PRT  \\\n",
            ".     0.126  0.043  0.107  0.052  0.080  0.120  0.216  0.029  0.067  0.022   \n",
            "ADJ   0.066  0.062  0.073  0.005  0.026  0.005  0.711  0.018  0.002  0.016   \n",
            "ADP   0.008  0.079  0.017  0.011  0.001  0.440  0.304  0.055  0.035  0.009   \n",
            "ADV   0.129  0.123  0.153  0.079  0.017  0.085  0.053  0.023  0.036  0.029   \n",
            "CONJ  0.018  0.112  0.061  0.059  0.000  0.147  0.336  0.025  0.041  0.025   \n",
            "DET   0.010  0.236  0.008  0.014  0.000  0.006  0.643  0.018  0.006  0.002   \n",
            "NOUN  0.251  0.017  0.216  0.021  0.049  0.012  0.254  0.010  0.013  0.017   \n",
            "NUM   0.230  0.071  0.136  0.038  0.031  0.009  0.413  0.015  0.004  0.007   \n",
            "PRON  0.066  0.010  0.046  0.056  0.012  0.013  0.007  0.001  0.008  0.020   \n",
            "PRT   0.040  0.018  0.098  0.031  0.008  0.081  0.041  0.012  0.002  0.009   \n",
            "VERB  0.065  0.052  0.172  0.076  0.010  0.179  0.126  0.017  0.032  0.066   \n",
            "X     0.212  0.000  0.071  0.010  0.010  0.000  0.131  0.000  0.000  0.010   \n",
            "\n",
            "       VERB      X  \n",
            ".     0.137  0.001  \n",
            "ADJ   0.016  0.000  \n",
            "ADP   0.039  0.000  \n",
            "ADV   0.274  0.000  \n",
            "CONJ  0.175  0.000  \n",
            "DET   0.056  0.001  \n",
            "NOUN  0.140  0.000  \n",
            "NUM   0.047  0.000  \n",
            "PRON  0.761  0.000  \n",
            "PRT   0.659  0.000  \n",
            "VERB  0.204  0.000  \n",
            "X     0.020  0.535  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "```python\n",
        "A = np.zeros((num_tags, num_tags))\n",
        "```\n",
        "\n",
        "Crea una **matriz de ceros** de tama√±o `(n√∫mero de etiquetas x n√∫mero de etiquetas)`, es decir, una cuadr√≠cula donde se guardar√°n las **probabilidades de transici√≥n entre etiquetas gramaticales**.\n",
        "\n",
        "### Recorriendo secuencias para contar transiciones\n",
        "\n",
        "```python\n",
        "for tags in tag_sequences:\n",
        "    for i in range(1, len(tags)):\n",
        "        prev_tag = tags[i-1]\n",
        "        curr_tag = tags[i]\n",
        "        A[tag2idx[prev_tag], tag2idx[curr_tag]] += 1\n",
        "```\n",
        "\n",
        "üß© Por cada oraci√≥n, compara **pares consecutivos de etiquetas** como:\n",
        "\n",
        "```python\n",
        "['DET', 'NOUN', 'VERB']\n",
        "```\n",
        "\n",
        "Esto genera transiciones:\n",
        "\n",
        "- `DET ‚Üí NOUN`\n",
        "- `NOUN ‚Üí VERB`\n",
        "\n",
        "Y suma 1 en la celda correspondiente de la matriz `A`.\n",
        "\n",
        "Visualmente:\n",
        "\n",
        "| De \\ A | DET | NOUN | VERB |\n",
        "| --- | --- | --- | --- |\n",
        "| **DET** | 0 | 10 | 2 |\n",
        "| **NOUN** | 1 | 3 | 8 |\n",
        "| **VERB** | 2 | 1 | 0 |\n",
        "\n",
        "### üß™ Normalizar filas\n",
        "\n",
        "```python\n",
        "A = A / A.sum(axis=1, keepdims=True)\n",
        "```\n",
        "\n",
        "Convierte los conteos en **probabilidades**, de modo que cada fila (transiciones desde una etiqueta) sume 1.\n",
        "\n",
        "As√≠, por ejemplo:\n",
        "\n",
        "```\n",
        "A[tag2idx['DET']] = [0.05, 0.85, 0.10]\n",
        "```\n",
        "\n",
        "Significa:\n",
        "\n",
        "üìå Si est√°s en `DET`, hay **85% de chance de ir a NOUN**, 10% a VERB, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Paso 5: Estimar B (matriz de emisi√≥n)\n",
        "\n",
        "La matriz B cuenta la frecuencia con que una palabra se observa bajo una etiqueta:"
      ],
      "metadata": {
        "id": "p_uUw75ofWug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(all_words)\n",
        "B = np.zeros((num_tags, num_words))\n",
        "\n",
        "for words, tags in zip(word_sequences, tag_sequences):\n",
        "    for word, tag in zip(words, tags):\n",
        "        w = word.lower()\n",
        "        B[tag2idx[tag], word2idx[w]] += 1\n",
        "\n",
        "# Normalizar por filas (cada fila suma 1)\n",
        "B = B / B.sum(axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "4tGHcUzYfVNA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imrprimire B para que se visualice en las filas las etiquetas y en las columnas las palabras\n",
        "\n",
        "print(pd.DataFrame(B, index=all_tags, columns=all_words).round(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyZYQsbyhakb",
        "outputId": "37775164-4959-4953-d86c-40dfa11bba10"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          !   $1  $1,000  $1,000,000  $1,000,000,000  $1,250,000  $1,500  \\\n",
            ".     0.003  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "ADJ   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "ADP   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "ADV   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "CONJ  0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "DET   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "NOUN  0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "NUM   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "PRON  0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "PRT   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "VERB  0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "X     0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "\n",
            "      $1,500,000  $1,600  $1,750,000  ...  zinman  zoe  zombies  zone  zones  \\\n",
            ".            0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "ADJ          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "ADP          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "ADV          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "CONJ         0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "DET          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "NOUN         0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "NUM          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "PRON         0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "PRT          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "VERB         0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "X            0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "\n",
            "      zoning  zoo  zubkovskaya  zurcher  zurich  \n",
            ".        0.0  0.0          0.0      0.0     0.0  \n",
            "ADJ      0.0  0.0          0.0      0.0     0.0  \n",
            "ADP      0.0  0.0          0.0      0.0     0.0  \n",
            "ADV      0.0  0.0          0.0      0.0     0.0  \n",
            "CONJ     0.0  0.0          0.0      0.0     0.0  \n",
            "DET      0.0  0.0          0.0      0.0     0.0  \n",
            "NOUN     0.0  0.0          0.0      0.0     0.0  \n",
            "NUM      0.0  0.0          0.0      0.0     0.0  \n",
            "PRON     0.0  0.0          0.0      0.0     0.0  \n",
            "PRT      0.0  0.0          0.0      0.0     0.0  \n",
            "VERB     0.0  0.0          0.0      0.0     0.0  \n",
            "X        0.0  0.0          0.0      0.0     0.0  \n",
            "\n",
            "[12 rows x 13735 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "```python\n",
        "num_words = len(all_words)\n",
        "B = np.zeros((num_tags, num_words))\n",
        "```\n",
        "\n",
        "Crea una **matriz de emisi√≥n** `B`, de tama√±o:\n",
        "\n",
        "```\n",
        "(num_etiquetas x num_palabras)\n",
        "```\n",
        "\n",
        "Cada celda representar√°:\n",
        "\n",
        "> ¬øCon qu√© probabilidad una etiqueta (como NOUN) \"emite\" una palabra (como dog)?\n",
        ">\n",
        "\n",
        "### Recorriendo palabras y etiquetas\n",
        "\n",
        "```python\n",
        "for words, tags in zip(word_sequences, tag_sequences):\n",
        "    for word, tag in zip(words, tags):\n",
        "        w = word.lower()\n",
        "        B[tag2idx[tag], word2idx[w]] += 1\n",
        "```\n",
        "\n",
        "Va palabra por palabra, etiqueta por etiqueta, y suma 1 en la celda correspondiente de la matriz `B`.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "- Palabra: `\"runs\"`\n",
        "- Etiqueta: `\"VERB\"`\n",
        "    \n",
        "    ‚Üí Suma 1 en: `B[VERB, runs]`\n",
        "    \n",
        "\n",
        "### Normalizaci√≥n por filas\n",
        "\n",
        "```python\n",
        "B = B / B.sum(axis=1, keepdims=True)\n",
        "```\n",
        "\n",
        "Convierte los conteos en **probabilidades reales**.\n",
        "\n",
        "Cada fila representa una etiqueta (`NOUN`, `VERB`, etc.) y **suma 1**.\n",
        "\n",
        "Ejemplo visual:\n",
        "\n",
        "| Etiqueta (fila) | ... 'dog' | 'runs' | 'quickly' | ... |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| **NOUN** | 0.045 | 0.001 | 0.000 | ... |\n",
        "| **VERB** | 0.000 | 0.080 | 0.002 | ... |\n",
        "| **ADV** | 0.000 | 0.000 | 0.140 | ... |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Listo! Ya tienemos œÄ, A y B a partir del Brown Corpus\n",
        "\n",
        "Estos tres componentes ahora nos permiten:\n",
        "\n",
        "- Usar **el algoritmo de Viterbi con datos reales**.\n",
        "- Evaluar frases reales del corpus.\n",
        "- Hacer comparaci√≥n entre la etiqueta predicha y la verdadera."
      ],
      "metadata": {
        "id": "cnsUEF4kg4b6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üöÄ **Paso 1: Seleccionar una oraci√≥n del Brown Corpus**\n",
        "\n",
        "Vamos a seleccionar una oraci√≥n del corpus, procesarla y aplicar el algoritmo de Viterbi para obtener la secuencia de etiquetas m√°s probable.\n",
        "\n",
        "Primero, seleccionamos una oraci√≥n del corpus:"
      ],
      "metadata": {
        "id": "fkXZQMcV9b8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar la primera oraci√≥n del Brown Corpus (etiquetada)\n",
        "sentence = brown.sents()[0]  # Primer oraci√≥n del corpus\n",
        "tagged_sentence = brown.tagged_sents(tagset='universal')[0]  # Primer oraci√≥n etiquetada\n",
        "print(\"Oraci√≥n original:\", ' '.join(sentence))\n",
        "print(\"Oraci√≥n etiquetada:\", tagged_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv6fjZMM9bMe",
        "outputId": "f1a3dca2-c52e-43c4-abe4-d1d814a7769d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oraci√≥n original: The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\n",
            "Oraci√≥n etiquetada: [('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üßë‚Äçüíª **Paso 2: Aplicar el algoritmo de Viterbi**\n",
        "\n",
        "Ahora que tenemos las matrices œÄ, A y B, aplicamos el algoritmo de **Viterbi** que ya implementamos, pero esta vez con una **oraci√≥n del corpus real**.\n",
        "\n",
        "### Parte 1: **Preparaci√≥n de los Datos**"
      ],
      "metadata": {
        "id": "DqVO3rqI-tt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir las palabras de la oraci√≥n a √≠ndices\n",
        "obs = [word.lower() for word in sentence]  # Convertir palabras a min√∫sculas\n",
        "obs_idx = [word2idx[word] if word in word2idx else 0 for word in obs]  # Mapeo a √≠ndices"
      ],
      "metadata": {
        "id": "OOjhsa1Q-wvr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Convertir las palabras de la oraci√≥n a min√∫sculas**:\n",
        "    - Aqu√≠, estamos tomando la **oraci√≥n original** (que es una lista de palabras) y convirtiendo cada palabra a **min√∫sculas** para normalizar la entrada. Esto asegura que \"Perro\" y \"perro\" se traten igual.\n",
        "2. **Mapear las palabras a √≠ndices**:\n",
        "    - convertimos cada palabra de la oraci√≥n **`obs`** a su √≠ndice correspondiente en el vocabulario utilizando el diccionario `word2idx`. Si una palabra no est√° en el vocabulario (por ejemplo, una palabra desconocida o fuera del conjunto de entrenamiento), se asigna el √≠ndice 0 (generalmente usado como \"palabra desconocida\").\n",
        "\n",
        "### Parte 2: **Inicializaci√≥n de Variables**"
      ],
      "metadata": {
        "id": "6Yy0wqAj-4ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# N√∫mero de estados y palabras\n",
        "T = len(obs)\n",
        "N = len(all_tags)\n",
        "\n",
        "# Inicializar matrices delta y backpointers\n",
        "delta = np.zeros((T, N))\n",
        "psi = np.zeros((T, N), dtype=int)"
      ],
      "metadata": {
        "id": "DkFZ4dnz-6C0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **N√∫mero de estados (N) y observaciones (T)**:\n",
        "    - **`T`** es el n√∫mero de palabras (o **observaciones**) en la oraci√≥n. Esto se obtiene a partir de la longitud de la lista `obs`.\n",
        "    - **`N`** es el n√∫mero de posibles **etiquetas** (o **estados**) que puede tener nuestra secuencia, que es igual al n√∫mero de etiquetas en `all_tags`.\n",
        "2. **Inicializaci√≥n de las matrices delta y psi**:\n",
        "    - **`delta`** es una matriz que almacenar√° las probabilidades de las secuencias de estados m√°s probables hasta el momento (una especie de \"probabilidad acumulada\").\n",
        "    - **`psi`** es una matriz de **backpointers** que nos ayudar√° a realizar el retroceso (retroceder en el tiempo para encontrar la mejor secuencia de estados).\n",
        "\n",
        "### Parte 3: **Inicializaci√≥n de las Matrices (Paso Base)**"
      ],
      "metadata": {
        "id": "2V2YgOh1-90E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializaci√≥n\n",
        "for s in range(N):\n",
        "    delta[0, s] = pi[s] * B[s, obs_idx[0]]\n",
        "    psi[0, s] = 0  # No hay backpointer en el primer paso"
      ],
      "metadata": {
        "id": "94FnxoDX_Apw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Inicializaci√≥n de `delta` y `psi` para el primer estado**:\n",
        "- Para el primer estado (**t = 0**), se calcula la probabilidad de que cada etiqueta sea el estado inicial dado por la f√≥rmula:\n",
        "    - **`pi[s]`**: Probabilidad inicial de la etiqueta.\n",
        "    - **`B[s, obs_idx[0]]`**: Probabilidad de la etiqueta **`s`** dada la primera palabra de la oraci√≥n (en su √≠ndice).\n",
        "- **`psi[0, s] = 0`**: No se necesita un backpointer en el primer paso porque no hay un paso anterior.\n",
        "\n",
        "### Parte 4: Recursi√≥n (Paso de Transici√≥n)"
      ],
      "metadata": {
        "id": "MoaBz3qu_Dfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursi√≥n\n",
        "for t in range(1, T):\n",
        "    for s in range(N):\n",
        "        prob = delta[t-1] * A[:, s] * B[s, obs_idx[t]]\n",
        "        delta[t, s] = np.max(prob)\n",
        "        psi[t, s] = np.argmax(prob)"
      ],
      "metadata": {
        "id": "IahyeGn2_Hs9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Recursi√≥n para calcular las probabilidades de transici√≥n**:\n",
        "    - **Iteraci√≥n sobre las palabras (t)**: Recorremos las palabras de la oraci√≥n desde la segunda palabra (ya que la primera fue inicializada en el paso anterior).\n",
        "    - **Iteraci√≥n sobre los estados (s)**: Para cada posible etiqueta (estado), calculamos la probabilidad de transici√≥n a ese estado.\n",
        "        - **`delta[t-1]`**: Probabilidad acumulada de los estados en el paso anterior.\n",
        "        - **`A[:, s]`**: Probabilidades de transici√≥n de todos los estados previos a la etiqueta `s` (esto da la probabilidad de pasar de un estado anterior a `s`).\n",
        "        - **`B[s, obs_idx[t]]`**: Probabilidad de emitir la palabra `t` dado que estamos en el estado `s`.\n",
        "    - **`delta[t, s] = np.max(prob)`**: Seleccionamos el valor m√°ximo de la probabilidad de las transiciones posibles, es decir, el valor m√°s alto de probabilidad de pasar de un estado anterior a `s` y emitir la palabra `t`.\n",
        "    - **`psi[t, s] = np.argmax(prob)`**: Almacenamos el √≠ndice del estado anterior que llev√≥ a la mejor probabilidad (esto es el backpointer para el retroceso).\n",
        "\n",
        "### Parte 5: **Terminaci√≥n**"
      ],
      "metadata": {
        "id": "MPZFGUAnBKt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Terminaci√≥n\n",
        "best_path = np.zeros(T, dtype=int)\n",
        "best_path[-1] = np.argmax(delta[T-1])"
      ],
      "metadata": {
        "id": "WfmZzkAyBLa_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Determinar el mejor estado final**:\n",
        "    - Al final de la secuencia (en la √∫ltima palabra), seleccionamos el estado con la mayor probabilidad de transici√≥n acumulada utilizando **`np.argmax(delta[T-1])`**. Este es el √∫ltimo estado en la secuencia m√°s probable.\n",
        "\n",
        "### Parte 6: **Retroceso (Recuperaci√≥n de la Secuencia de Etiquetas)**"
      ],
      "metadata": {
        "id": "Loqs9u4aBPvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retroceso\n",
        "for t in range(T-2, -1, -1):\n",
        "    best_path[t] = psi[t+1, best_path[t+1]]\n",
        "\n",
        "print(best_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oviQOumkBSe1",
        "outputId": "ea5ce49c-63f8-4da8-83de-3e6cebe0cee4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5  6  6  1  6 10  6  5  6  2  6  1  6  6 10  0  5  6  0  2  5  6 10  6\n",
            "  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Retroceso para encontrar la secuencia √≥ptima de etiquetas**:\n",
        "    - **Retrocedemos en el tiempo** desde el pen√∫ltimo estado hasta el primero, utilizando los **backpointers** almacenados en la matriz `psi` para reconstruir la secuencia √≥ptima de etiquetas.\n",
        "    - **`best_path[t] = psi[t+1, best_path[t+1]]`**: Aqu√≠, para cada paso, recuperamos el estado anterior que llev√≥ al mejor estado actual y lo almacenamos en `best_path`.\n",
        "\n",
        "### Parte 7: Conversi√≥n de √çndices a Nombres de Etiquetas"
      ],
      "metadata": {
        "id": "UnmmE5YrBZmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir los √≠ndices de las etiquetas a nombres\n",
        "predicted_tags = [all_tags[s] for s in best_path]"
      ],
      "metadata": {
        "id": "4uI7d03Vk005"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Convertir los √≠ndices de las etiquetas a sus nombres**:\n",
        "    - Aqu√≠, convertimos los √≠ndices almacenados en `best_path` (la secuencia √≥ptima de estados) a sus **nombres de etiquetas** correspondientes utilizando el conjunto `all_tags`. Esto nos da la secuencia de etiquetas predicha por el modelo.\n",
        "\n",
        "### Parte 8: **Mostrar Resultados**"
      ],
      "metadata": {
        "id": "-iEsQ9Q_k3VL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar resultados\n",
        "print(\"\\nEtiquetas predichas:\")\n",
        "print(predicted_tags)\n",
        "\n",
        "# Mostrar etiquetas reales\n",
        "real_tags = [tag for word, tag in tagged_sentence]\n",
        "print(\"\\nEtiquetas reales:\")\n",
        "print(real_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz5rvvrrk5yt",
        "outputId": "3eeff157-ab5a-451e-e3bf-f0b5a520c015"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Etiquetas predichas:\n",
            "['DET', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'VERB', '.', 'DET', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.']\n",
            "\n",
            "Etiquetas reales:\n",
            "['DET', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'VERB', '.', 'DET', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Mostrar las etiquetas predichas**:\n",
        "    - Extraemos las **etiquetas reales** de la oraci√≥n etiquetada utilizando una comprensi√≥n de listas. Estas son las etiquetas que deber√≠an corresponder a las palabras en la oraci√≥n.\n",
        "\n",
        "### Parte 9: **Comparar Predicciones con Realidad**"
      ],
      "metadata": {
        "id": "C3d_In12k-4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparar\n",
        "correct = sum([1 for p, r in zip(predicted_tags, real_tags) if p == r])\n",
        "print(f\"\\nPorcentaje de precisi√≥n: {correct / len(real_tags) * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu2mbom4lBRq",
        "outputId": "f58bd87d-7c63-42c1-d1ed-a7964b164d9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Porcentaje de precisi√≥n: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Comparar las etiquetas predichas con las reales**:\n",
        "    - Comparamos las **etiquetas predichas** con las **etiquetas reales** y calculamos la precisi√≥n. La precisi√≥n es el porcentaje de etiquetas que el modelo predijo correctamente en relaci√≥n con el total de etiquetas reales.\n",
        "    - **`correct`** cuenta cu√°ntas veces las etiquetas predichas coinciden con las reales.\n",
        "    - Luego, calculamos el **porcentaje de precisi√≥n** y lo imprimimos."
      ],
      "metadata": {
        "id": "0EjfE42MlMOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Validacion con un conjunto mas grande partir del Brown Corpus\n",
        "\n",
        "Estrategia para la validacion:\n",
        "\n",
        "- **Seleccionar un conjunto de oraciones** del Brown Corpus.\n",
        "- **Aplicar el algoritmo de Viterbi** a cada oraci√≥n.\n",
        "- **Calcular la precisi√≥n** comparando las etiquetas predichas con las reales.\n",
        "- **Promediar la precisi√≥n** de todas las oraciones para obtener una medida general.\n",
        "\n",
        "### C√≥digo para validaci√≥n con un conjunto m√°s grande (500 oraciones):"
      ],
      "metadata": {
        "id": "2LuFFZj41YsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar un subconjunto m√°s grande de oraciones (por ejemplo, 500 oraciones)\n",
        "tagged_sents = brown.tagged_sents(tagset='universal')[:500]\n",
        "\n",
        "# Inicializar contadores\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Evaluar todas las oraciones en el conjunto\n",
        "for tagged_sentence in tagged_sents:\n",
        "    sentence = [word for word, tag in tagged_sentence]\n",
        "    real_tags = [tag for word, tag in tagged_sentence]\n",
        "\n",
        "    # Convertir las palabras de la oraci√≥n a √≠ndices\n",
        "    obs_idx = [word2idx[word.lower()] if word.lower() in word2idx else 0 for word in sentence]  # √≠ndice de palabras\n",
        "\n",
        "    # Inicializar las matrices delta y backpointers\n",
        "    delta = np.zeros((len(sentence), len(all_tags)))\n",
        "    psi = np.zeros((len(sentence), len(all_tags)), dtype=int)\n",
        "\n",
        "    # Inicializaci√≥n\n",
        "    for s in range(len(all_tags)):\n",
        "        delta[0, s] = pi[s] * B[s, obs_idx[0]]\n",
        "        psi[0, s] = 0\n",
        "\n",
        "    # Recursi√≥n\n",
        "    for t in range(1, len(sentence)):\n",
        "        for s in range(len(all_tags)):\n",
        "            prob = delta[t-1] * A[:, s] * B[s, obs_idx[t]]\n",
        "            delta[t, s] = np.max(prob)\n",
        "            psi[t, s] = np.argmax(prob)\n",
        "\n",
        "    # Terminaci√≥n\n",
        "    best_path = np.zeros(len(sentence), dtype=int)\n",
        "    best_path[-1] = np.argmax(delta[len(sentence)-1])\n",
        "\n",
        "    # Retroceso\n",
        "    for t in range(len(sentence)-2, -1, -1):\n",
        "        best_path[t] = psi[t+1, best_path[t+1]]\n",
        "\n",
        "    # Convertir los √≠ndices de las etiquetas a nombres\n",
        "    predicted_tags = [all_tags[s] for s in best_path]\n",
        "\n",
        "    # Comparar las etiquetas predichas con las reales\n",
        "    correct += sum([1 for p, r in zip(predicted_tags, real_tags) if p == r])\n",
        "    total += len(real_tags)\n",
        "\n",
        "# Calcular la precisi√≥n promedio\n",
        "precision = correct / total * 100\n",
        "print(f\"\\nPrecisi√≥n en el conjunto de 500 oraciones: {precision:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUyMGOhQlOA_",
        "outputId": "b8e87166-2d9f-45cb-9dca-9327bd41efba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Precisi√≥n en el conjunto de 500 oraciones: 98.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explicaci√≥n del c√≥digo**:\n",
        "\n",
        "1. **Seleccionar oraciones**: Seleccionamos las primeras 500 oraciones del Brown Corpus etiquetadas con el tagset simplificado.\n",
        "2. **Aplicar el modelo de Viterbi** a cada oraci√≥n: Procesamos cada oraci√≥n como lo hicimos antes, pero ahora lo hacemos para todas las oraciones en el conjunto.\n",
        "3. **Contar los aciertos**: Para cada oraci√≥n, comparamos las etiquetas predichas con las reales y contamos cu√°ntas coincidencias encontramos.\n",
        "4. **Calcular la precisi√≥n**: Promediamos los resultados de todas las oraciones para obtener una precisi√≥n global.\n",
        "\n",
        "### üèÖ **¬øQu√© significa el resultado?**\n",
        "\n",
        "- **Precisi√≥n muy alta**: El modelo de HMM est√° funcionando realmente bien, y est√° etiquetando correctamente la mayor√≠a de las oraciones del corpus.\n",
        "- **Generalizaci√≥n**: El hecho de que el modelo haya funcionado tan bien en un conjunto grande de datos sugiere que ha aprendido patrones generales de la estructura gramatical y de las transiciones entre etiquetas POS."
      ],
      "metadata": {
        "id": "6JzTDSHn1mDu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUk9O5qV1m0L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}