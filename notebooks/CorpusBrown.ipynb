{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ ¬øQu√© haremos en esta parte?\n",
        "\n",
        "### **Objetivo**:\n",
        "\n",
        "Usar el **Brown Corpus** (un corpus etiquetado del ingl√©s) para:\n",
        "\n",
        "- Probar el algoritmo de Viterbi.\n",
        "- Validar los resultados en una oraci√≥n real etiquetada.\n",
        "- Comparar la secuencia etiquetada con la secuencia ‚Äúverdadera‚Äù.\n",
        "\n",
        "## üîß PASOS PARA AVANZAR:\n",
        "\n",
        "### üì¶ Paso 1: Instalar y cargar el corpus Brown\n",
        "\n",
        "Usaremos **NLTK**, una librer√≠a muy com√∫n para NLP en Python.\n",
        "\n",
        "```bash\n",
        "pip install nltk\n",
        "```\n",
        "\n",
        "C√≥digo para cargar una parte del corpus:"
      ],
      "metadata": {
        "id": "LPdpJlJF_lDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3lXVJ62j07Z",
        "outputId": "bdff2ad3-cafb-4ac1-987d-0d77b4eaf162"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "- Se importa la biblioteca **NLTK (Natural Language Toolkit)**, una de las bibliotecas m√°s utilizadas en Python para procesamiento de lenguaje natural. Contiene herramientas para tareas como tokenizaci√≥n, etiquetado gramatical (POS tagging), an√°lisis sint√°ctico, etc.\n",
        "- Se descarga el **Brown Corpus**, uno de los corpus m√°s antiguos y ampliamente utilizados en ling√º√≠stica computacional. Es una colecci√≥n de textos en ingl√©s estadounidense divididos en categor√≠as tem√°ticas. Se usa para entrenar y probar modelos de lenguaje, an√°lisis gramatical, etc.\n",
        "- Se descarga el **Universal Tagset**, que es un conjunto simplificado y estandarizado de etiquetas gramaticales (como `NOUN`, `VERB`, `ADJ`, etc.). Sirve para facilitar comparaciones entre lenguajes o corpus que utilizan diferentes conjuntos de etiquetas.\n",
        "\n",
        "---\n",
        "\n",
        "Luego, cargamos las oraciones etiquetadas con un **tagset universal** (simplificado, como NOUN, VERB, etc.):"
      ],
      "metadata": {
        "id": "oLUJx19PAHRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "\n",
        "# Obtener oraciones etiquetadas (solo las 5000 primeras para empezar)\n",
        "tagged_sents = brown.tagged_sents(tagset='universal')[:5000]\n",
        "tagged_sents[:1] # Visualizacion de la primera oracion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUCuW-kXj8QU",
        "outputId": "a5be1fbb-8e21-4d18-c9ca-074928630b7f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('The', 'DET'),\n",
              "  ('Fulton', 'NOUN'),\n",
              "  ('County', 'NOUN'),\n",
              "  ('Grand', 'ADJ'),\n",
              "  ('Jury', 'NOUN'),\n",
              "  ('said', 'VERB'),\n",
              "  ('Friday', 'NOUN'),\n",
              "  ('an', 'DET'),\n",
              "  ('investigation', 'NOUN'),\n",
              "  ('of', 'ADP'),\n",
              "  (\"Atlanta's\", 'NOUN'),\n",
              "  ('recent', 'ADJ'),\n",
              "  ('primary', 'NOUN'),\n",
              "  ('election', 'NOUN'),\n",
              "  ('produced', 'VERB'),\n",
              "  ('``', '.'),\n",
              "  ('no', 'DET'),\n",
              "  ('evidence', 'NOUN'),\n",
              "  (\"''\", '.'),\n",
              "  ('that', 'ADP'),\n",
              "  ('any', 'DET'),\n",
              "  ('irregularities', 'NOUN'),\n",
              "  ('took', 'VERB'),\n",
              "  ('place', 'NOUN'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "- Se importa el **corpus Brown** desde el m√≥dulo `nltk.corpus`. Esto nos da acceso directo al contenido del corpus, como palabras, oraciones y sus etiquetas gramaticales.\n",
        "- `brown.tagged_sents(tagset='universal')`:\n",
        "    - Esto obtiene las oraciones del corpus **Brown**, donde cada palabra est√° **etiquetada gramaticalmente** (por ejemplo: 'the/DET', 'dog/NOUN').\n",
        "    - El par√°metro `tagset='universal'` convierte las etiquetas del corpus a un conjunto **simplificado y estandarizado** de etiquetas gramaticales universales (como `NOUN`, `VERB`, `ADP`, etc.), en lugar del conjunto original del Brown Corpus."
      ],
      "metadata": {
        "id": "cWT8d7-BAVfl"
      }
    }
  ]
}