{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Â¿QuÃ© haremos en esta parte?\n",
        "\n",
        "### **Objetivo**:\n",
        "\n",
        "Usar el **Brown Corpus** (un corpus etiquetado del inglÃ©s) para:\n",
        "\n",
        "- Probar el algoritmo de Viterbi.\n",
        "- Validar los resultados en una oraciÃ³n real etiquetada.\n",
        "- Comparar la secuencia etiquetada con la secuencia â€œverdaderaâ€.\n",
        "\n",
        "## ðŸ”§ PASOS PARA AVANZAR:\n",
        "\n",
        "### ðŸ“¦ Paso 1: Instalar y cargar el corpus Brown\n",
        "\n",
        "Usaremos **NLTK**, una librerÃ­a muy comÃºn para NLP en Python.\n",
        "\n",
        "```bash\n",
        "pip install nltk\n",
        "```\n",
        "\n",
        "CÃ³digo para cargar una parte del corpus:"
      ],
      "metadata": {
        "id": "LPdpJlJF_lDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3lXVJ62j07Z",
        "outputId": "bdff2ad3-cafb-4ac1-987d-0d77b4eaf162"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "- Se importa la biblioteca **NLTK (Natural Language Toolkit)**, una de las bibliotecas mÃ¡s utilizadas en Python para procesamiento de lenguaje natural. Contiene herramientas para tareas como tokenizaciÃ³n, etiquetado gramatical (POS tagging), anÃ¡lisis sintÃ¡ctico, etc.\n",
        "- Se descarga el **Brown Corpus**, uno de los corpus mÃ¡s antiguos y ampliamente utilizados en lingÃ¼Ã­stica computacional. Es una colecciÃ³n de textos en inglÃ©s estadounidense divididos en categorÃ­as temÃ¡ticas. Se usa para entrenar y probar modelos de lenguaje, anÃ¡lisis gramatical, etc.\n",
        "- Se descarga el **Universal Tagset**, que es un conjunto simplificado y estandarizado de etiquetas gramaticales (como `NOUN`, `VERB`, `ADJ`, etc.). Sirve para facilitar comparaciones entre lenguajes o corpus que utilizan diferentes conjuntos de etiquetas.\n",
        "\n",
        "\n",
        "âœ… **Resumen Visual:**\n",
        "\n",
        "```\n",
        "[NLTK] ---> [Brown Corpus ðŸ“˜] + [Universal POS Tags ðŸ·ï¸]\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Luego, cargamos las oraciones etiquetadas con un **tagset universal** (simplificado, como NOUN, VERB, etc.):"
      ],
      "metadata": {
        "id": "oLUJx19PAHRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "\n",
        "# Obtener oraciones etiquetadas (solo las 5000 primeras para empezar)\n",
        "tagged_sents = brown.tagged_sents(tagset='universal')[:5000]\n",
        "tagged_sents[:1] # Visualizacion de la primera oracion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUCuW-kXj8QU",
        "outputId": "42c458d7-2610-4f1e-cd3c-3e6ce10aaf36"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('The', 'DET'),\n",
              "  ('Fulton', 'NOUN'),\n",
              "  ('County', 'NOUN'),\n",
              "  ('Grand', 'ADJ'),\n",
              "  ('Jury', 'NOUN'),\n",
              "  ('said', 'VERB'),\n",
              "  ('Friday', 'NOUN'),\n",
              "  ('an', 'DET'),\n",
              "  ('investigation', 'NOUN'),\n",
              "  ('of', 'ADP'),\n",
              "  (\"Atlanta's\", 'NOUN'),\n",
              "  ('recent', 'ADJ'),\n",
              "  ('primary', 'NOUN'),\n",
              "  ('election', 'NOUN'),\n",
              "  ('produced', 'VERB'),\n",
              "  ('``', '.'),\n",
              "  ('no', 'DET'),\n",
              "  ('evidence', 'NOUN'),\n",
              "  (\"''\", '.'),\n",
              "  ('that', 'ADP'),\n",
              "  ('any', 'DET'),\n",
              "  ('irregularities', 'NOUN'),\n",
              "  ('took', 'VERB'),\n",
              "  ('place', 'NOUN'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "- Se importa el **corpus Brown** desde el mÃ³dulo `nltk.corpus`. Esto nos da acceso directo al contenido del corpus, como palabras, oraciones y sus etiquetas gramaticales.\n",
        "- `brown.tagged_sents(tagset='universal')`:\n",
        "    - Esto obtiene las oraciones del corpus **Brown**, donde cada palabra estÃ¡ **etiquetada gramaticalmente** (por ejemplo: 'the/DET', 'dog/NOUN').\n",
        "    - El parÃ¡metro `tagset='universal'` convierte las etiquetas del corpus a un conjunto **simplificado y estandarizado** de etiquetas gramaticales universales (como `NOUN`, `VERB`, `ADP`, etc.), en lugar del conjunto original del Brown Corpus.\n",
        "---\n",
        "\n",
        "### ðŸ§  Paso 2: Extraer listas de etiquetas y palabras\n",
        "\n",
        "Vamos a obtener todas las **etiquetas** y **palabras** del corpus y crear un **vocabulario y conjunto de etiquetas Ãºnicos**:"
      ],
      "metadata": {
        "id": "cWT8d7-BAVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listas vacÃ­as para almacenar\n",
        "tag_sequences = []\n",
        "word_sequences = []\n",
        "\n",
        "for sent in tagged_sents:\n",
        "    words, tags = zip(*sent)\n",
        "    word_sequences.append(list(words))\n",
        "    tag_sequences.append(list(tags))\n",
        "\n",
        "print(\"Word despues del Zip\", words)\n",
        "print(\"Tags despues del Zip\", tags)\n",
        "print(\"Word secuence\", word_sequences[-2:])\n",
        "print(\"Tag secuence\", tag_sequences[-2:])\n",
        "\n",
        "\n",
        "# Vocabulario de palabras y etiquetas\n",
        "all_tags = sorted(set(tag for tags in tag_sequences for tag in tags))\n",
        "all_words = sorted(set(word.lower() for words in word_sequences for word in words))\n",
        "\n",
        "# Crear Ã­ndices\n",
        "tag2idx = {tag: i for i, tag in enumerate(all_tags)}\n",
        "word2idx = {word: i for i, word in enumerate(all_words)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbpUa5cLL3x4",
        "outputId": "7a29860d-413d-4752-d98f-cd5d4da7f189"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word despues del Zip ('Does', 'it', 'attack', 'other', 'traditional', 'American', 'institutions', 'with', 'unsupportable', 'and', 'wild', 'charges', '?', '?')\n",
            "Tags despues del Zip ('VERB', 'PRON', 'VERB', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'CONJ', 'ADJ', 'NOUN', '.', '.')\n",
            "Word secuence [['2', '.'], ['Does', 'it', 'attack', 'other', 'traditional', 'American', 'institutions', 'with', 'unsupportable', 'and', 'wild', 'charges', '?', '?']]\n",
            "Tag secuence [['NUM', '.'], ['VERB', 'PRON', 'VERB', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'CONJ', 'ADJ', 'NOUN', '.', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Todas las palabras\", all_words[900:920])\n",
        "print(\"Todas las etiquetas\", all_tags)\n",
        "print(\"Indices de palabras\", dict(list(word2idx.items())[900:920]))\n",
        "print(\"Indices de etiquetas\", tag2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78kZnwgKWcAh",
        "outputId": "195bf4fa-d588-4df7-eef9-39d1184b072f"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todas las palabras ['accused', 'ace', 'achaeans', \"achaeans'\", 'achieve', 'achieved', 'achievement', 'achievements', 'achieves', 'aching', 'acid', 'acknowledge', 'acknowledged', 'acknowledging', 'acknowledgment', 'acquaint', 'acquaintance', 'acquiesce', 'acquiesced', 'acquire']\n",
            "Todas las etiquetas ['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "Indices de palabras {'accused': 900, 'ace': 901, 'achaeans': 902, \"achaeans'\": 903, 'achieve': 904, 'achieved': 905, 'achievement': 906, 'achievements': 907, 'achieves': 908, 'aching': 909, 'acid': 910, 'acknowledge': 911, 'acknowledged': 912, 'acknowledging': 913, 'acknowledgment': 914, 'acquaint': 915, 'acquaintance': 916, 'acquiesce': 917, 'acquiesced': 918, 'acquire': 919}\n",
            "Indices de etiquetas {'.': 0, 'ADJ': 1, 'ADP': 2, 'ADV': 3, 'CONJ': 4, 'DET': 5, 'NOUN': 6, 'NUM': 7, 'PRON': 8, 'PRT': 9, 'VERB': 10, 'X': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "| Parte | DescripciÃ³n |\n",
        "| --- | --- |\n",
        "| `tag_sequences`, `word_sequences` | ðŸ“„ Listas para guardar solo las palabras y etiquetas de cada oraciÃ³n |\n",
        "| `zip(*sent)` | Separa cada oraciÃ³n etiquetada en dos listas: palabras y etiquetas |\n",
        "| `set(... for ...)` | Extrae todas las **palabras Ãºnicas** (en minÃºscula) y **etiquetas Ãºnicas** |\n",
        "| `enumerate(...)` | Asigna un **Ã­ndice numÃ©rico** a cada palabra y etiqueta |\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **Resumen visual paso a paso:**\n",
        "\n",
        "```\n",
        "1. [('The', 'DET'), ('dog', 'NOUN')] â†’ zip â†’ ['The', 'dog'], ['DET', 'NOUN']\n",
        "2. word_sequences = [['The', 'dog'], ...]\n",
        "3. tag_sequences  = [['DET', 'NOUN'], ...]\n",
        "\n",
        "4. all_words = ['a', 'about', 'accident', ...]  â†’ word2idx = {'a': 0, 'about': 1, ...}\n",
        "5. all_tags  = ['ADJ', 'ADV', 'DET', ...]      â†’ tag2idx  = {'ADJ': 0, 'ADV': 1, ...}\n",
        "```\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Paso 3: Estimar Ï€ (probabilidades iniciales)\n",
        "\n",
        "La probabilidad Ï€ representa quÃ© **tan seguido cada etiqueta inicia una oraciÃ³n**:"
      ],
      "metadata": {
        "id": "5PH1AeK7RNS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_tags = len(all_tags)\n",
        "pi = np.zeros(num_tags)\n",
        "\n",
        "# Contar cuÃ¡ntas veces comienza una oraciÃ³n con cada etiqueta\n",
        "for tags in tag_sequences:\n",
        "    first_tag = tags[0]\n",
        "    pi[tag2idx[first_tag]] += 1\n",
        "\n",
        "# Normalizar\n",
        "pi /= pi.sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "kmhqOtakRglD"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimire pi mostrando a que etiqueta corresponde esa probabilida y cual fue su conteo\n",
        "for i, p in enumerate(pi):\n",
        "    print(f\"{all_tags[i]}: {p:.4f} ({pi[i] * len(tag_sequences):.0f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se-i5gvaeTG6",
        "outputId": "aa1e8734-6106-4167-d186-727bc90e9e5a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".: 0.0824 (412)\n",
            "ADJ: 0.0460 (230)\n",
            "ADP: 0.1006 (503)\n",
            "ADV: 0.0578 (289)\n",
            "CONJ: 0.0380 (190)\n",
            "DET: 0.2470 (1235)\n",
            "NOUN: 0.2520 (1260)\n",
            "NUM: 0.0164 (82)\n",
            "PRON: 0.0952 (476)\n",
            "PRT: 0.0272 (136)\n",
            "VERB: 0.0368 (184)\n",
            "X: 0.0006 (3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "### Vector de estados iniciales `Ï€`\n",
        "\n",
        "```python\n",
        "num_tags = len(all_tags)     # Total de etiquetas (estados)\n",
        "pi = np.zeros(num_tags)      # Inicializa un vector de ceros\n",
        "```\n",
        "\n",
        "Se crea un vector llamado `pi` que guardarÃ¡ **la probabilidad de comenzar una oraciÃ³n con cada etiqueta gramatical**.\n",
        "\n",
        "Visualmente serÃ­a algo asÃ­ como:\n",
        "\n",
        "```\n",
        "pi = [0, 0, 0, 0, ...]  â† uno por cada etiqueta (NOUN, VERB, DET, etc.)\n",
        "```\n",
        "\n",
        "### Contar etiquetas iniciales\n",
        "\n",
        "```python\n",
        "for tags in tag_sequences:\n",
        "    first_tag = tags[0]\n",
        "    pi[tag2idx[first_tag]] += 1\n",
        "```\n",
        "\n",
        "Recorre todas las oraciones y **cuenta con quÃ© etiqueta comienza cada una**.\n",
        "\n",
        "Ejemplo\n",
        "\n",
        "- Si una oraciÃ³n empieza con `DET`, suma 1 al Ã­ndice correspondiente en `pi`.\n",
        "\n",
        "### NormalizaciÃ³n\n",
        "\n",
        "```python\n",
        "pi /= pi.sum()\n",
        "```\n",
        "\n",
        "Convierte los conteos en **probabilidades reales** (todas suman 1).\n",
        "\n",
        "ðŸ“Š Ejemplo conceptual:\n",
        "\n",
        "| Etiqueta inicial | Conteo | Probabilidad (Ï€) |\n",
        "| --- | --- | --- |\n",
        "| DET | 2000 | 0.40 |\n",
        "| NOUN | 1500 | 0.30 |\n",
        "| VERB | 1500 | 0.30 |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”„ Paso 4: Estimar A (matriz de transiciÃ³n)\n",
        "\n",
        "La matriz A cuenta la frecuencia con que una etiqueta es seguida por otra:"
      ],
      "metadata": {
        "id": "A7bEnzsBdoLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.zeros((num_tags, num_tags))\n",
        "\n",
        "for tags in tag_sequences:\n",
        "    for i in range(1, len(tags)):\n",
        "        prev_tag = tags[i-1]\n",
        "        curr_tag = tags[i]\n",
        "        A[tag2idx[prev_tag], tag2idx[curr_tag]] += 1\n",
        "\n",
        "# Normalizar por filas (para que cada fila sume 1)\n",
        "A = A / A.sum(axis=1, keepdims=True)\n"
      ],
      "metadata": {
        "id": "G51-w0eCd2oa"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#imprimire la matriz A donde las columas y filas tengan de nombre las etiquetas\n",
        "print(pd.DataFrame(A, index=all_tags, columns=all_tags).round(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0ECtdQYfmE3",
        "outputId": "8b470aba-f924-4d7f-a9f5-3315473e6e8e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          .    ADJ    ADP    ADV   CONJ    DET   NOUN    NUM   PRON    PRT  \\\n",
            ".     0.126  0.043  0.107  0.052  0.080  0.120  0.216  0.029  0.067  0.022   \n",
            "ADJ   0.066  0.062  0.073  0.005  0.026  0.005  0.711  0.018  0.002  0.016   \n",
            "ADP   0.008  0.079  0.017  0.011  0.001  0.440  0.304  0.055  0.035  0.009   \n",
            "ADV   0.129  0.123  0.153  0.079  0.017  0.085  0.053  0.023  0.036  0.029   \n",
            "CONJ  0.018  0.112  0.061  0.059  0.000  0.147  0.336  0.025  0.041  0.025   \n",
            "DET   0.010  0.236  0.008  0.014  0.000  0.006  0.643  0.018  0.006  0.002   \n",
            "NOUN  0.251  0.017  0.216  0.021  0.049  0.012  0.254  0.010  0.013  0.017   \n",
            "NUM   0.230  0.071  0.136  0.038  0.031  0.009  0.413  0.015  0.004  0.007   \n",
            "PRON  0.066  0.010  0.046  0.056  0.012  0.013  0.007  0.001  0.008  0.020   \n",
            "PRT   0.040  0.018  0.098  0.031  0.008  0.081  0.041  0.012  0.002  0.009   \n",
            "VERB  0.065  0.052  0.172  0.076  0.010  0.179  0.126  0.017  0.032  0.066   \n",
            "X     0.212  0.000  0.071  0.010  0.010  0.000  0.131  0.000  0.000  0.010   \n",
            "\n",
            "       VERB      X  \n",
            ".     0.137  0.001  \n",
            "ADJ   0.016  0.000  \n",
            "ADP   0.039  0.000  \n",
            "ADV   0.274  0.000  \n",
            "CONJ  0.175  0.000  \n",
            "DET   0.056  0.001  \n",
            "NOUN  0.140  0.000  \n",
            "NUM   0.047  0.000  \n",
            "PRON  0.761  0.000  \n",
            "PRT   0.659  0.000  \n",
            "VERB  0.204  0.000  \n",
            "X     0.020  0.535  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "```python\n",
        "A = np.zeros((num_tags, num_tags))\n",
        "```\n",
        "\n",
        "Crea una **matriz de ceros** de tamaÃ±o `(nÃºmero de etiquetas x nÃºmero de etiquetas)`, es decir, una cuadrÃ­cula donde se guardarÃ¡n las **probabilidades de transiciÃ³n entre etiquetas gramaticales**.\n",
        "\n",
        "### Recorriendo secuencias para contar transiciones\n",
        "\n",
        "```python\n",
        "for tags in tag_sequences:\n",
        "    for i in range(1, len(tags)):\n",
        "        prev_tag = tags[i-1]\n",
        "        curr_tag = tags[i]\n",
        "        A[tag2idx[prev_tag], tag2idx[curr_tag]] += 1\n",
        "```\n",
        "\n",
        "ðŸ§© Por cada oraciÃ³n, compara **pares consecutivos de etiquetas** como:\n",
        "\n",
        "```python\n",
        "['DET', 'NOUN', 'VERB']\n",
        "```\n",
        "\n",
        "Esto genera transiciones:\n",
        "\n",
        "- `DET â†’ NOUN`\n",
        "- `NOUN â†’ VERB`\n",
        "\n",
        "Y suma 1 en la celda correspondiente de la matriz `A`.\n",
        "\n",
        "Visualmente:\n",
        "\n",
        "| De \\ A | DET | NOUN | VERB |\n",
        "| --- | --- | --- | --- |\n",
        "| **DET** | 0 | 10 | 2 |\n",
        "| **NOUN** | 1 | 3 | 8 |\n",
        "| **VERB** | 2 | 1 | 0 |\n",
        "\n",
        "### ðŸ§ª Normalizar filas\n",
        "\n",
        "```python\n",
        "A = A / A.sum(axis=1, keepdims=True)\n",
        "```\n",
        "\n",
        "Convierte los conteos en **probabilidades**, de modo que cada fila (transiciones desde una etiqueta) sume 1.\n",
        "\n",
        "AsÃ­, por ejemplo:\n",
        "\n",
        "```\n",
        "A[tag2idx['DET']] = [0.05, 0.85, 0.10]\n",
        "```\n",
        "\n",
        "Significa:\n",
        "\n",
        "ðŸ“Œ Si estÃ¡s en `DET`, hay **85% de chance de ir a NOUN**, 10% a VERB, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“ˆ Paso 5: Estimar B (matriz de emisiÃ³n)\n",
        "\n",
        "La matriz B cuenta la frecuencia con que una palabra se observa bajo una etiqueta:"
      ],
      "metadata": {
        "id": "p_uUw75ofWug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(all_words)\n",
        "B = np.zeros((num_tags, num_words))\n",
        "\n",
        "for words, tags in zip(word_sequences, tag_sequences):\n",
        "    for word, tag in zip(words, tags):\n",
        "        w = word.lower()\n",
        "        B[tag2idx[tag], word2idx[w]] += 1\n",
        "\n",
        "# Normalizar por filas (cada fila suma 1)\n",
        "B = B / B.sum(axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "4tGHcUzYfVNA"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imrprimire B para que se visualice en las filas las etiquetas y en las columnas las palabras para los valores donde no sean 0.0\n",
        "\n",
        "print(pd.DataFrame(B, index=all_tags, columns=all_words).round(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyZYQsbyhakb",
        "outputId": "a7c6580c-716b-4ce7-f440-3850fa67d56b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          !   $1  $1,000  $1,000,000  $1,000,000,000  $1,250,000  $1,500  \\\n",
            ".     0.003  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "ADJ   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "ADP   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "ADV   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "CONJ  0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "DET   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "NOUN  0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "NUM   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "PRON  0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "PRT   0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "VERB  0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "X     0.000  0.0     0.0         0.0             0.0         0.0     0.0   \n",
            "\n",
            "      $1,500,000  $1,600  $1,750,000  ...  zinman  zoe  zombies  zone  zones  \\\n",
            ".            0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "ADJ          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "ADP          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "ADV          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "CONJ         0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "DET          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "NOUN         0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "NUM          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "PRON         0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "PRT          0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "VERB         0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "X            0.0     0.0         0.0  ...     0.0  0.0      0.0   0.0    0.0   \n",
            "\n",
            "      zoning  zoo  zubkovskaya  zurcher  zurich  \n",
            ".        0.0  0.0          0.0      0.0     0.0  \n",
            "ADJ      0.0  0.0          0.0      0.0     0.0  \n",
            "ADP      0.0  0.0          0.0      0.0     0.0  \n",
            "ADV      0.0  0.0          0.0      0.0     0.0  \n",
            "CONJ     0.0  0.0          0.0      0.0     0.0  \n",
            "DET      0.0  0.0          0.0      0.0     0.0  \n",
            "NOUN     0.0  0.0          0.0      0.0     0.0  \n",
            "NUM      0.0  0.0          0.0      0.0     0.0  \n",
            "PRON     0.0  0.0          0.0      0.0     0.0  \n",
            "PRT      0.0  0.0          0.0      0.0     0.0  \n",
            "VERB     0.0  0.0          0.0      0.0     0.0  \n",
            "X        0.0  0.0          0.0      0.0     0.0  \n",
            "\n",
            "[12 rows x 13735 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicacion del codigo:\n",
        "\n",
        "```python\n",
        "num_words = len(all_words)\n",
        "B = np.zeros((num_tags, num_words))\n",
        "```\n",
        "\n",
        "Crea una **matriz de emisiÃ³n** `B`, de tamaÃ±o:\n",
        "\n",
        "```\n",
        "(num_etiquetas x num_palabras)\n",
        "```\n",
        "\n",
        "Cada celda representarÃ¡:\n",
        "\n",
        "> Â¿Con quÃ© probabilidad una etiqueta (como NOUN) \"emite\" una palabra (como dog)?\n",
        ">\n",
        "\n",
        "### Recorriendo palabras y etiquetas\n",
        "\n",
        "```python\n",
        "for words, tags in zip(word_sequences, tag_sequences):\n",
        "    for word, tag in zip(words, tags):\n",
        "        w = word.lower()\n",
        "        B[tag2idx[tag], word2idx[w]] += 1\n",
        "```\n",
        "\n",
        "Va palabra por palabra, etiqueta por etiqueta, y suma 1 en la celda correspondiente de la matriz `B`.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "- Palabra: `\"runs\"`\n",
        "- Etiqueta: `\"VERB\"`\n",
        "    \n",
        "    â†’ Suma 1 en: `B[VERB, runs]`\n",
        "    \n",
        "\n",
        "### NormalizaciÃ³n por filas\n",
        "\n",
        "```python\n",
        "B = B / B.sum(axis=1, keepdims=True)\n",
        "```\n",
        "\n",
        "Convierte los conteos en **probabilidades reales**.\n",
        "\n",
        "Cada fila representa una etiqueta (`NOUN`, `VERB`, etc.) y **suma 1**.\n",
        "\n",
        "Ejemplo visual:\n",
        "\n",
        "| Etiqueta (fila) | ... 'dog' | 'runs' | 'quickly' | ... |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| **NOUN** | 0.045 | 0.001 | 0.000 | ... |\n",
        "| **VERB** | 0.000 | 0.080 | 0.002 | ... |\n",
        "| **ADV** | 0.000 | 0.000 | 0.140 | ... |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Listo! Ya tienemos Ï€, A y B a partir del Brown Corpus\n",
        "\n",
        "Estos tres componentes ahora nos permiten:\n",
        "\n",
        "- Usar **el algoritmo de Viterbi con datos reales**.\n",
        "- Evaluar frases reales del corpus.\n",
        "- Hacer comparaciÃ³n entre la etiqueta predicha y la verdadera."
      ],
      "metadata": {
        "id": "cnsUEF4kg4b6"
      }
    }
  ]
}